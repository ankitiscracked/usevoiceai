---
title: What is usevoiceai?
icon: Rocket
---

`usevoiceai` is the toolkit for building ambitious voice AI apps. It's a set of packages that help you build voice AI apps quickly and easily. It's build on typescript and is framework agnostic. It's inspired by [AI SDK](https://sdk.vercel.ai/) and [Pipecat](https://pipecat.dev/).

usevoiceai has two main parts for the minimum setup required to get up and running.

- Client: `useVoice` and `useAudio` hooks which are the main interfaces for capturing speech and playing the response speech on web clients.
- Server: Voice session, session adapters for transports such a Durable Objects websockets, Node websockets, etc., and STT/TTS/agent provider scaffolding.

It's heavily inspired by [AI SDK](https://sdk.vercel.ai/) and [Pipecat](https://pipecat.dev/) so the API is hugely inspired by them. Greate DX is a top priority.

Here's the minimum setup required to get up and running.

```ts
import { useVoice, useAudio } from "usevoiceai";

const { startRecording, stopRecording, transcript, audioStream } = useVoice();
const { stop } = useAudio(audioStream);
```

```ts
import { VoiceSessionDO } from "usevoiceai";

const VoiceSessionDO = createVoiceDurableObject<Env>({
  transcription: (env) => deepgram("nova-3", { apiKey: env.DEEPGRAM_API_KEY }),
  agent: (env) => new MockAgentProcessor(env),
  speech: (env) => cartesia("sonic-3", { apiKey: env.CARTESIA_API_KEY }),
});

export default {
  async fetch(request: Request, env: Env) {
    const url = new URL(request.url);

    if (url.pathname === "/voice-command/ws") {
      const userId = url.searchParams.get("userId") ?? "demo-user";
      const id = env.VOICE_SESSION.newUniqueId();
      const stub = env.VOICE_SESSION.get(id);
      return stub.fetch(new Request(request, { headers }));
    }
    return new Response("Not found", { status: 404 });
  },
};
```

<Cards>
  <Card
    title="Learn more about Tanstack Start"
    href="https://tanstack.com/start"
  />
  <Card title="Learn more about Fumadocs" href="https://fumadocs.dev" />
</Cards>

### Problems it solves

Voice models have gotten really good lately but the infra to stitch everything together is lacking. Model providers have their SDKs but every provider have different interfaces. We have frameworks like Pipecat which are great but I needed something like AI SDK to get from idea to prod as soon as it is possible. In fact, the API is hugely inspired by AI SDK. So `usevoiceai` is an attempt to build something sophisticated with the same API simplicity and engineer ergonomics.

Some of the problems it solves:

- **Framework Agnostic**: It's framework agnostic so you can use it with any framework you want.
- **Easy to use**: The API is designed to be easy to use and understand.
- **Great DX**: The API is designed to be easy to use and understand.
- **Great DX**: The API is designed to be easy to use and understand.

## Pluggable providers

`usevoiceai` is designed to be pluggable so you can use any provider you want. We have a few providers out of the box:

- **STT**: [Deepgram](https://deepgram.com/)
- **TTS**: [Cartesia](https://cartesia.ai/)
- **Agent**: [MockAgent](https://mockagent.com/)

You can also create your own provider by implementing the `AgentProcessor` interface.

```ts title="agent-processor.ts"
import { AgentProcessor } from "usevoiceai";

class MockAgentProcessor implements AgentProcessor {
  constructor(private env: Env) {}
  async process({
    transcript,
    send,
  }: Parameters<AgentProcessor["process"]>[0]) {
    // do something with the transcript and return response
    await send({ type: "complete", data: { responseText: response } });
  }
}
```
